{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data_generator_helper import generate_synthetic_selection_dataset\n",
    "from data_generator_helper import generate_synthetic_operation_dataset\n",
    "from models_new.nalu import NALU\n",
    "from models_new.nac import NAC\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.mplot3d import Axes3D as plt3\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportLoss(loss):\n",
    "    print(loss)\n",
    "    \n",
    "def train(model, optimizer, x_train, y_train, epochs, batch_size, model_param):\n",
    "    '''\n",
    "    if model_param == \"NAC\":\n",
    "        weights = np.zeros((epochs,len(x_train)//batch_size,out_dim,sample_size,3))\n",
    "    elif model_param == \"NALU\":\n",
    "        weights = np.zeros((epochs,len(x_train)//batch_size,out_dim,sample_size,4))\n",
    "        g_prev = np.zeros((epochs,len(x_train)//batch_size,out_dim))\n",
    "    \n",
    "    '''\n",
    "    losses = np.zeros((epochs,len(x_train)//batch_size))\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(len(x_train) // batch_size):\n",
    "            '''\n",
    "            # Save weights\n",
    "            for children in model.model.children():\n",
    "                plist = [param for param in children.parameters()]\n",
    "                if model_param == \"NAC\":\n",
    "                    W_hat = plist[0]\n",
    "                    M_hat = plist[1]\n",
    "                elif model_param == \"NALU\":\n",
    "                    W_hat = plist[1]\n",
    "                    M_hat = plist[2]\n",
    "                    weights[epoch,batch,:,:,3] = plist[0].detach().numpy()\n",
    "                W = torch.tanh(W_hat) * torch.sigmoid(M_hat)\n",
    "                weights[epoch,batch,:,:,0] = W_hat.detach().numpy()\n",
    "                weights[epoch,batch,:,:,1] = M_hat.detach().numpy()\n",
    "                weights[epoch,batch,:,:,2] = W.detach().numpy()\n",
    "            '''\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_batch_train = x_train[batch:(batch+batch_size),:]\n",
    "            y_batch_train = y_train[batch:(batch+batch_size),:]\n",
    "            '''\n",
    "            if model_param == \"NALU\":\n",
    "                g_prev[epoch,batch,:] = F.linear(plist[0],x_batch_train,).detach().numpy().flatten()\n",
    "                #print(np.shape(g_prev),np.shape(F.linear(plist[0],x_batch_train).detach().numpy()))\n",
    "            '''\n",
    "            out = model(x_batch_train)\n",
    "    \n",
    "            loss = F.mse_loss(out, y_batch_train)\n",
    "            \n",
    "            if loss != loss:\n",
    "                print(\"nan detected\")\n",
    "            #losses[epoch,batch] = loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "           \n",
    "    return test(model,x_train,y_train),losses\n",
    "\n",
    "     \n",
    "    \n",
    "def test(model, x_test, y_test):\n",
    "    model.eval()\n",
    "    output_test = model(x_test)\n",
    "    loss = F.mse_loss(output_test, y_test)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "operators = [\"add\",\"sub\",\"mult\",\"div\",\"square\",\"root\"]\n",
    "init = 'Kai_uni'\n",
    "model_param =  \"NALU\"\n",
    "\n",
    "test_per_range = 10\n",
    "sample_size = 2\n",
    "set_size = 100\n",
    "\n",
    "in_dim = sample_size\n",
    "hidden_dim = 1\n",
    "out_dim = 1\n",
    "num_layers = 1\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "batch_size = 1\n",
    "values = [[0,1],[-1,1],[0,100],[-100,100]]\n",
    "for op in operators:\n",
    "    print(\"Operator: \" + str(op))\n",
    "    for j, value in tqdm(enumerate(values)):\n",
    "\n",
    "        min_value = value[0]\n",
    "        max_value = value[1]\n",
    "\n",
    "        #print(\"Test range: \"+str(values))\n",
    "        print(\"Train range: [\"+str(min_value)+\",\"+str(max_value)+\"]\")\n",
    "        for k in range(test_per_range):\n",
    "            avgloss = np.zeros(4)\n",
    "            exploss = 0\n",
    "            i=0\n",
    "            if model_param == \"NALU\":\n",
    "                model = NALU(num_layers, in_dim, hidden_dim, out_dim,init)\n",
    "            elif model_param == \"NAC\":\n",
    "                model = NAC(num_layers, in_dim, hidden_dim, out_dim, init)\n",
    "            optimizer = torch.optim.RMSprop(model.parameters(),lr=lr)\n",
    "\n",
    "            x_train, y_train = generate_synthetic_operation_dataset(op,min_value, \n",
    "                                                                                max_value, sample_size, \n",
    "                                                                                set_size, boundaries = None)\n",
    "\n",
    "            x_test, y_test = generate_synthetic_operation_dataset(op,min_value, max_value,\n",
    "                                                             sample_size, set_size, boundaries = None)\n",
    "\n",
    "            x_train = x_train.type(torch.DoubleTensor)\n",
    "            y_train = y_train.type(torch.DoubleTensor)\n",
    "            x_test = x_test.type(torch.DoubleTensor)\n",
    "            y_test = y_test.type(torch.DoubleTensor)\n",
    "\n",
    "            loss,losses = train(model, optimizer, x_train, y_train, epochs, batch_size, model_param)\n",
    "            filename = str(op)+\"_\"+str(min_value)+\"_\"+str(max_value)+\"_\"+str(k)\n",
    "            np.save(filename,losses)\n",
    "            out = loss.data.numpy() / np.max(x_test.data.numpy())\n",
    "            #print(\"Interpolation Loss: \",'{:.2e}'.format(out))\n",
    "            exploss = exploss + out\n",
    "            #print(\"Extrapolation Loss: \", end='')\n",
    "            for idx,val in enumerate(values):\n",
    "                \n",
    "                x_test, y_test = generate_synthetic_operation_dataset(op,val[0], val[1],\n",
    "                                                                 sample_size, set_size, boundaries = None)\n",
    "\n",
    "                x_test = x_test.type(torch.DoubleTensor)\n",
    "                y_test = y_test.type(torch.DoubleTensor)               \n",
    "                test_loss  = test(model, x_test, y_test)\n",
    "                out = test_loss.data.numpy() #/ np.max(x_test.data.numpy())\n",
    "                avgloss[idx] = avgloss[idx] + out\n",
    "                #print('{:.2e}'.format(out), end=' ')\n",
    "        print('{:.2e}'.format(exploss/10))\n",
    "        for avgl in avgloss:\n",
    "            print('{:.2e}'.format(avgl/10), end=' ') \n",
    "        print('\\n')\n",
    "            #print('')\n",
    "        #print('\\n')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

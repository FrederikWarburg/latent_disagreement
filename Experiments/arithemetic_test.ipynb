{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.nalu import NALU\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.nac import NeuralAccumulatorCell\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "\n",
    "class NeuralArithmeticLogicUnitCell(nn.Module):\n",
    "    \"\"\"A Neural Arithmetic Logic Unit (NALU) cell [1].\n",
    "    Attributes:\n",
    "        in_dim: size of the input sample.\n",
    "        out_dim: size of the output sample.\n",
    "    Sources:\n",
    "        [1]: https://arxiv.org/abs/1808.00508\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.eps = 1e-10\n",
    "\n",
    "        self.G = Parameter(torch.Tensor(out_dim, in_dim))\n",
    "        self.nac = NeuralAccumulatorCell(in_dim, out_dim)\n",
    "        self.register_parameter('bias', None)\n",
    "\n",
    "        init.kaiming_uniform_(self.G, a=math.sqrt(5))\n",
    "\n",
    "    def forward(self, input):\n",
    "        a = self.nac(input)\n",
    "        g = torch.sigmoid(F.linear(input, self.G, self.bias))\n",
    "        add_sub = g * a\n",
    "        log_input = torch.log(torch.abs(input) + self.eps)\n",
    "        m = torch.exp(self.nac(log_input))\n",
    "        mul_div = (1 - g) * m\n",
    "        y = add_sub + mul_div\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_dim={}, out_dim={}'.format(\n",
    "            self.in_dim, self.out_dim\n",
    "        )\n",
    "\n",
    "\n",
    "class NALU(nn.Module):\n",
    "    \"\"\"A stack of NAC layers.\n",
    "    Attributes:\n",
    "        num_layers: the number of NAC layers.\n",
    "        in_dim: the size of the input sample.\n",
    "        hidden_dim: the size of the hidden layers.\n",
    "        out_dim: the size of the output.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(\n",
    "                NeuralArithmeticLogicUnitCell(\n",
    "                    hidden_dim if i > 0 else in_dim,\n",
    "                    hidden_dim if i < num_layers - 1 else out_dim,\n",
    "                )\n",
    "            )\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_arithmetic_dataset(arithmetic_op, min_value, max_value, sample_size, set_size, boundaries = None):\n",
    "    \"\"\"\n",
    "    generates a dataset of integers for the synthetics arithmetic task\n",
    "    :param arithmetic_op: the type of operation to perform on the sum of the two sub sections can be either :\n",
    "    [\"add\" , \"subtract\", \"multiply\", \"divide\", \"root\", \"square\"]\n",
    "    :param min_value: the minimum possible value of the generated integers\n",
    "    :param max_value: the maximum possible value of the generated integers\n",
    "    :param sample_size: the number of integers per sample\n",
    "    :param set_size: the number of samples in the dataset\n",
    "    :param boundaries: [Optional] an iterable of 4 integer indices in the following format :\n",
    "    [start of 1st section, end of 1st section, start of 2nd section, end of 2nd section]\n",
    "    if None, the boundaries are randomly generated.\n",
    "    :return: the training dataset input, the training true outputs, the boundaries of the sub sections used\n",
    "    \"\"\"\n",
    "    scaled_input_values = np.random.randint(min_value, max_value, (set_size, sample_size))\n",
    "\n",
    "    if boundaries is None:\n",
    "        boundaries = [np.random.randint(sample_size) for i in range(4)]\n",
    "        boundaries[1] = np.random.randint(boundaries[0], sample_size)\n",
    "        boundaries[3] = np.random.randint(boundaries[2], sample_size)\n",
    "    else:\n",
    "        if len(boundaries) != 4:\n",
    "            raise ValueError(\"boundaries is expected to be a list of 4 elements but found {}\".format(len(boundaries)))\n",
    "\n",
    "    a = np.array([np.sum(sample[boundaries[0]:boundaries[1]]) for sample in scaled_input_values])\n",
    "    b = np.array([np.sum(sample[boundaries[2]:boundaries[3]]) for sample in scaled_input_values])\n",
    "    true_outputs = None\n",
    "    if \"add\" in str.lower(arithmetic_op):\n",
    "        true_outputs = a + b\n",
    "    elif \"sub\" in str.lower(arithmetic_op):\n",
    "        true_outputs = a - b\n",
    "    elif \"mult\" in str.lower(arithmetic_op):\n",
    "        true_outputs = a * b\n",
    "    elif \"div\" in str.lower(arithmetic_op):\n",
    "        true_outputs = a / b\n",
    "    elif \"square\" == str.lower(arithmetic_op):\n",
    "        true_outputs = a * a\n",
    "    elif \"root\" in str.lower(arithmetic_op):\n",
    "        true_outputs = np.sqrt(a)\n",
    "\n",
    "    return scaled_input_values, true_outputs, boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  (100000, 10) (100000,)\n",
      "Test size: (100000, 10) (100000,)\n",
      "Training X min and max:  -1000 999\n",
      "Training y min and max:  -3992 3988\n",
      "Test X min and max:  -10000 9999\n",
      "Test y min and max:  -39800 39820\n",
      "Boundaries:  [5, 7, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.01\n",
    "FEATURES_NUM = 10\n",
    "batch_size = 12800 # or whatever\n",
    "\n",
    "X_train, y_train, boundaries = generate_synthetic_arithmetic_dataset(\"add\", -1000, 1000, FEATURES_NUM, 100000)\n",
    "X_test, y_test, _ = generate_synthetic_arithmetic_dataset(\"add\", -10000, 10000, FEATURES_NUM, 100000, boundaries)\n",
    "\n",
    "print(\"Training size: \", np.shape(X_train), np.shape(y_train))\n",
    "print(\"Test size:\", np.shape(X_test), np.shape(y_test))\n",
    "\n",
    "print(\"Training X min and max: \", np.min(X_train),np.max(X_train))\n",
    "print(\"Training y min and max: \", np.min(y_train),np.max(y_train))\n",
    "\n",
    "print(\"Test X min and max: \", np.min(X_test),np.max(X_test))\n",
    "print(\"Test y min and max: \", np.min(y_test),np.max(y_test))\n",
    "\n",
    "print(\"Boundaries: \", boundaries)\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test).unsqueeze(1)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train).unsqueeze(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NALU(\n",
      "  (model): Sequential(\n",
      "    (0): NeuralArithmeticLogicUnitCell(\n",
      "      in_dim=10, out_dim=2\n",
      "      (nac): NeuralAccumulatorCell(in_dim=10, out_dim=2)\n",
      "    )\n",
      "    (1): NeuralArithmeticLogicUnitCell(\n",
      "      in_dim=2, out_dim=1\n",
      "      (nac): NeuralAccumulatorCell(in_dim=2, out_dim=1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_dim = 10\n",
    "hidden_dim = 2\n",
    "out_dim = 1\n",
    "num_layers = 2\n",
    "\n",
    "net = NALU(num_layers, in_dim, hidden_dim, out_dim)\n",
    "optim = torch.optim.RMSprop(net.parameters(),lr=LEARNING_RATE)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, data, target, optimizer):\n",
    "    \n",
    "    training_loss = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        permutation = torch.randperm(data.size()[0])\n",
    "        for i in range(0,data.size()[0], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = data[indices], target[indices]\n",
    "                \n",
    "            out = model(batch_x)\n",
    "\n",
    "            loss = F.mse_loss(out, batch_y)\n",
    "            training_loss.append(loss)\n",
    "        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, target):\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        return torch.abs(target - out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1180cf828>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = training(net, X_train, y_train, optim)\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e+06 *\n",
       "       2.4618)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test(net, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

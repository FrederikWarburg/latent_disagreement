{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nac import NAC\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data_generator_helper import generate_synthetic_selection_dataset\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss as MSE\n",
    "\n",
    "def test(model, x_test, y_test):\n",
    "    loss = nn.MSELoss()\n",
    "    model.eval()\n",
    "    output_test = model(x_test)\n",
    "    loss = loss(output_test, y_test)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightfile = 'convtest_NALU_Ones_test_3.npy'\n",
    "weights, losses, bounds, sample_size, out_dim, epochs, its, g_prevs = np.load(weightfile)\n",
    "temp = weights[0][0][-1,-1,:,:,:]\n",
    "W_hat = temp[:,:,0]\n",
    "M_hat = temp[:,:,1]\n",
    "W = temp[:,:,2]\n",
    "G = temp[:,:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralAccumulatorCell(nn.Module):\n",
    "    \"\"\"A Neural Accumulator (NAC) cell [1].\n",
    "\n",
    "    Attributes:\n",
    "        in_dim: size of the input sample.\n",
    "        out_dim: size of the output sample.\n",
    "\n",
    "    Sources:\n",
    "        [1]: https://arxiv.org/abs/1808.00508\n",
    "    \"\"\"\n",
    "    def __init__(self, What, Mhat):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.What = What#Parameter(torch.Tensor(out_dim, in_dim))\n",
    "        self.Mhat = Mhat#Parameter(torch.Tensor(out_dim, in_dim))\n",
    "\n",
    "        self.register_parameter('W_hat', self.What)\n",
    "        self.register_parameter('M_hat', self.Mhat)\n",
    "        self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, input):\n",
    "        W = torch.tanh(self.What) * torch.sigmoid(self.Mhat)\n",
    "        return F.linear(input, W, self.bias)\n",
    "\n",
    "\n",
    "class NeuralArithmeticLogicUnitCell(nn.Module):\n",
    "    \"\"\"A Neural Arithmetic Logic Unit (NALU) cell [1].\n",
    "\n",
    "    Attributes:\n",
    "        in_dim: size of the input sample.\n",
    "        out_dim: size of the output sample.\n",
    "\n",
    "    Sources:\n",
    "        [1]: https://arxiv.org/abs/1808.00508\n",
    "    \"\"\"\n",
    "    def __init__(self, G, What, Mhat):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = 1e-10\n",
    "\n",
    "        self.G = G\n",
    "        self.nac = NeuralAccumulatorCell(What, Mhat)\n",
    "        self.register_parameter('bias', None)\n",
    "    \n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        a = self.nac(input)\n",
    "        g = torch.sigmoid(F.linear(input, self.G, self.bias))\n",
    "\n",
    "        add_sub = g * a\n",
    "        log_input = torch.log(torch.abs(input) + self.eps)\n",
    "\n",
    "        m = torch.exp(self.nac(log_input))\n",
    "\n",
    "        mul_div = (1 - g) * m\n",
    "        y = add_sub + mul_div\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, numpy.float64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[0,0],type(G[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = torch.Tensor(G)\n",
    "G = torch.nn.Parameter(G.type(torch.DoubleTensor))\n",
    "W_hat = torch.Tensor(W_hat)\n",
    "W_hat = torch.nn.Parameter(W_hat.type(torch.DoubleTensor))\n",
    "M_hat = torch.Tensor(M_hat)\n",
    "M_hat = torch.nn.Parameter(M_hat.type(torch.DoubleTensor))\n",
    "\n",
    "model = NeuralArithmeticLogicUnitCell(G, W_hat, M_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 100]), torch.Size([2, 100]), torch.Size([2, 100]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(G), np.shape(W_hat), np.shape(M_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.387712434366338e-08\n",
      "0.0005664076238968713\n",
      "1.0444664161538606e-06\n",
      "6.126072214472623e+39\n",
      "1.5438243626209182e+64\n",
      "0.6881436360393461\n"
     ]
    }
   ],
   "source": [
    "test_per_range = 1\n",
    "sample_size = 100\n",
    "set_size = 100\n",
    "\n",
    "in_dim = sample_size\n",
    "hidden_dim = 1\n",
    "out_dim = 2\n",
    "num_layers = 1\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "#values = np.linspace(1,1000,10)\n",
    "values = [[0.0,1.0],\n",
    "          [-0.001, 0.001],\n",
    "          [0.0,100.0],\n",
    "          [-100.0,100.0],\n",
    "          [-1000.0,1000.0],\n",
    "          [-1.0,1.0]]\n",
    "\n",
    "for value in values:\n",
    "    min_value, max_value=  value\n",
    "\n",
    "    x_test, y_test, _ = generate_synthetic_selection_dataset(min_value, max_value,\n",
    "                                                                sample_size, set_size, boundaries = bounds[0][0])\n",
    "\n",
    "    x_test = x_test.type(torch.DoubleTensor)\n",
    "    y_test = y_test.type(torch.DoubleTensor)\n",
    "    test_loss  = test(model, x_test, y_test)\n",
    "\n",
    "    print(float(test_loss.data.numpy())/torch.max(x_test).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.4463,  4.6190], dtype=torch.float64, grad_fn=<SelectBackward>)\n",
      "tensor([0.9024, 2.1096], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "weightfile = 'nntest_NALU_[\\'NALU\\']_test_22_50.npy'\n",
    "out = np.load(weightfile)\n",
    "data = out[1]\n",
    "w1 = data[0][0].double()\n",
    "b1 = data[0][1].double()\n",
    "w2 = data[2][0].double()\n",
    "b2 = data[2][1].double()\n",
    "\n",
    "k1 = F.linear(x_test,w1)\n",
    "k2 = k1+b1\n",
    "k3 = F.linear(k2,w2)\n",
    "k4 = k3+b2\n",
    "v = 10\n",
    "print(k4[v,:])\n",
    "print(y_test[v,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nntest_NALU_['NALU']_test_0_2_50_100.npy\n",
      "1.5908613926457666\n",
      "25397.913736081275\n",
      "1009.1401081566196\n",
      "990.4139796171725\n",
      "9759.784672545507\n",
      "36.01126898297484\n",
      "nntest_NALU_['NALU']_test_1_2_50_100.npy\n",
      "0.8880948662311533\n",
      "23436.821219501195\n",
      "1801.133432992231\n",
      "587.7638878711247\n",
      "5919.64327899\n",
      "31.66429423169649\n",
      "nntest_NALU_['NALU']_test_2_2_50_100.npy\n",
      "0.5431079555336887\n",
      "22770.759352205627\n",
      "1270.1476144566182\n",
      "554.1233911547836\n",
      "4800.181885365624\n",
      "27.323166147510733\n",
      "nntest_NALU_['NALU']_test_3_2_50_100.npy\n",
      "0.4733716973777383\n",
      "18005.088088650125\n",
      "1377.3568646401695\n",
      "480.322123496499\n",
      "4974.480400071965\n",
      "26.10149378691088\n",
      "nntest_NALU_['NALU']_test_4_2_50_100.npy\n",
      "3.0793538456534386\n",
      "54187.334248876534\n",
      "1551.5749116923785\n",
      "1895.3682821870318\n",
      "18211.243496942374\n",
      "77.61918446588143\n",
      "nntest_NALU_['NALU']_test_5_2_50_100.npy\n",
      "1.183094937895295\n",
      "94250.60812487072\n",
      "2655.7503055652633\n",
      "945.7321515843074\n",
      "8928.981739551498\n",
      "96.59777629458857\n",
      "nntest_NALU_['NALU']_test_6_2_50_100.npy\n",
      "3.803165920908013\n",
      "180466.09711344176\n",
      "4171.335238496792\n",
      "1479.1986548814482\n",
      "18683.43710558462\n",
      "200.24139443099398\n",
      "nntest_NALU_['NALU']_test_7_2_50_100.npy\n",
      "0.7425038202798561\n",
      "9325.337366715168\n",
      "1332.7726756221823\n",
      "386.99207591339837\n",
      "3874.535681451245\n",
      "12.978652362229813\n",
      "nntest_NALU_['NALU']_test_8_2_50_100.npy\n",
      "0.6868340325149455\n",
      "9802.962456477228\n",
      "1818.2226888410214\n",
      "452.2434735740739\n",
      "3771.920265919545\n",
      "14.93254308780809\n",
      "nntest_NALU_['NALU']_test_9_2_50_100.npy\n",
      "2.828521967304406\n",
      "117610.78105386507\n",
      "10362.397616474169\n",
      "2499.9511898040096\n",
      "23154.82420956679\n",
      "169.91250916384607\n"
     ]
    }
   ],
   "source": [
    "test_per_range = 1\n",
    "sample_size = 100\n",
    "set_size = 100\n",
    "\n",
    "in_dim = sample_size\n",
    "hidden_dim = 1\n",
    "out_dim = 2\n",
    "num_layers = 1\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "shit = ['nntest_NALU_[\\'NALU\\']_test_0_2_50_100.npy', 'nntest_NALU_[\\'NALU\\']_test_1_2_50_100.npy',\n",
    "'nntest_NALU_[\\'NALU\\']_test_2_2_50_100.npy', 'nntest_NALU_[\\'NALU\\']_test_3_2_50_100.npy',\n",
    "'nntest_NALU_[\\'NALU\\']_test_4_2_50_100.npy', 'nntest_NALU_[\\'NALU\\']_test_5_2_50_100.npy',\n",
    "'nntest_NALU_[\\'NALU\\']_test_6_2_50_100.npy', 'nntest_NALU_[\\'NALU\\']_test_7_2_50_100.npy',\n",
    "'nntest_NALU_[\\'NALU\\']_test_8_2_50_100.npy', 'nntest_NALU_[\\'NALU\\']_test_9_2_50_100.npy']\n",
    "    \n",
    "for weightfile in shit:\n",
    "    #weightfile = 'nntest_NALU_[\\'NALU\\']_test_2_2_50_100.npy'\n",
    "    print(weightfile)\n",
    "    #weightfile = 'nntest_NALU_[\\'NALU\\']_test_02_50.npy'\n",
    "    out = np.load(weightfile)\n",
    "    data = out[1]\n",
    "    bounds = out[2]\n",
    "    w1 = data[0][0].double()\n",
    "    b1 = data[0][1].double()\n",
    "    w2 = data[2][0].double()\n",
    "    b2 = data[2][1].double()\n",
    "\n",
    "\n",
    "    #values = np.linspace(1,1000,10)\n",
    "    values = [[0.0,1.0],\n",
    "              [-0.001, 0.001],\n",
    "              [0.0,100.0],\n",
    "              [-100.0,100.0],\n",
    "              [-1000.0,1000.0],\n",
    "              [-1.0,1.0]]\n",
    "\n",
    "    for value in values:\n",
    "        min_value, max_value=  value\n",
    "\n",
    "        x_test, y_test, _ = generate_synthetic_selection_dataset(min_value, max_value,\n",
    "                                                                    sample_size, set_size, boundaries = bounds)\n",
    "\n",
    "        x_test = x_test.type(torch.DoubleTensor)\n",
    "        y_test = y_test.type(torch.DoubleTensor)\n",
    "\n",
    "        loss = nn.MSELoss()\n",
    "\n",
    "        k1 = F.linear(x_test,w1)\n",
    "        k2 = F.relu(k1+b1)\n",
    "        k3 = F.linear(k2,w2)\n",
    "        k4 = F.relu(k3+b2)\n",
    "\n",
    "        #print(np.shape(k4))\n",
    "        #print(np.shape(y_test))\n",
    "        test_loss = loss(k4,y_test)\n",
    "\n",
    "        #test_loss  = test(model, x_test, y_test)\n",
    "        print(float(test_loss.data.numpy())/torch.max(x_test).numpy())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
